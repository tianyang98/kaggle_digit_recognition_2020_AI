{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ai-input/scan-train-labels.npy\n",
      "/kaggle/input/ai-input/scan-train-images.npy\n",
      "/kaggle/input/ai-input-test/scan-test-images.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.2361 - accuracy: 0.9289 - val_loss: 0.0548 - val_accuracy: 0.9839\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0740 - accuracy: 0.9777 - val_loss: 0.0378 - val_accuracy: 0.9877\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.0340 - val_accuracy: 0.9889\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.0277 - val_accuracy: 0.9910\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.0285 - val_accuracy: 0.9912\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0325 - accuracy: 0.9901 - val_loss: 0.0270 - val_accuracy: 0.9906\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.0280 - val_accuracy: 0.9915\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.0276 - val_accuracy: 0.9907\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.0287 - val_accuracy: 0.9915\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0299 - val_accuracy: 0.9917\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0288 - val_accuracy: 0.9902\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0317 - val_accuracy: 0.9901\n",
      "Test loss: 0.03167638285419607\n",
      "Test accuracy: 0.9901000261306763\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (3780, 28, 28)\n",
      "train_y shape: (3780,)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.load('/kaggle/input/ai-input/scan-train-images.npy')\n",
    "train_y = np.load('/kaggle/input/ai-input/scan-train-labels.npy')\n",
    "print(\"train_x shape:\", train_x.shape)\n",
    "print(\"train_y shape:\", train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], img_rows, img_cols, 1)\n",
    "train_y = keras.utils.to_categorical(train_y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (3780, 28, 28, 1)\n",
      "train_y shape: (3780, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x shape:\", train_x.shape)\n",
    "print(\"train_y shape:\", train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 39.96351602704604\n",
      "Test accuracy: 0.9711640477180481\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(train_x, train_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: (60000, 28, 28)\n",
      "y1 shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x1, y1), (xt, yt) = mnist.load_data()\n",
    "print(\"x1 shape:\", x1.shape)\n",
    "print(\"y1 shape:\", y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000, 10)\n",
      "x_test shape: (10000, 28, 28, 1)\n",
      "y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3780 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "3780/3780 [==============================] - 0s 128us/step - loss: 24.7047 - accuracy: 0.9595 - val_loss: 1.5249 - val_accuracy: 0.7480\n",
      "Epoch 2/12\n",
      "3780/3780 [==============================] - 0s 127us/step - loss: 4.9189 - accuracy: 0.9728 - val_loss: 2.1877 - val_accuracy: 0.2580\n",
      "Epoch 3/12\n",
      "3780/3780 [==============================] - 0s 121us/step - loss: 2.5651 - accuracy: 0.9683 - val_loss: 2.2675 - val_accuracy: 0.1981\n",
      "Epoch 4/12\n",
      "3780/3780 [==============================] - 0s 124us/step - loss: 1.3850 - accuracy: 0.9757 - val_loss: 2.2873 - val_accuracy: 0.1918\n",
      "Epoch 5/12\n",
      "3780/3780 [==============================] - 0s 118us/step - loss: 0.9078 - accuracy: 0.9701 - val_loss: 2.2780 - val_accuracy: 0.1928\n",
      "Epoch 6/12\n",
      "3780/3780 [==============================] - 0s 122us/step - loss: 0.8387 - accuracy: 0.9780 - val_loss: 2.2977 - val_accuracy: 0.1517\n",
      "Epoch 7/12\n",
      "3780/3780 [==============================] - 0s 121us/step - loss: 0.5752 - accuracy: 0.9780 - val_loss: 2.2960 - val_accuracy: 0.1607\n",
      "Epoch 8/12\n",
      "3780/3780 [==============================] - 0s 124us/step - loss: 0.4320 - accuracy: 0.9823 - val_loss: 2.2917 - val_accuracy: 0.1805\n",
      "Epoch 9/12\n",
      "3780/3780 [==============================] - 0s 120us/step - loss: 0.4472 - accuracy: 0.9762 - val_loss: 2.2998 - val_accuracy: 0.1366\n",
      "Epoch 10/12\n",
      "3780/3780 [==============================] - 0s 123us/step - loss: 0.2979 - accuracy: 0.9854 - val_loss: 2.2988 - val_accuracy: 0.1501\n",
      "Epoch 11/12\n",
      "3780/3780 [==============================] - 0s 119us/step - loss: 0.3524 - accuracy: 0.9839 - val_loss: 2.2959 - val_accuracy: 0.1534\n",
      "Epoch 12/12\n",
      "3780/3780 [==============================] - 0s 126us/step - loss: 0.2951 - accuracy: 0.9870 - val_loss: 2.2978 - val_accuracy: 0.1420\n",
      "Test loss: 2.2978007522583006\n",
      "Test accuracy: 0.1420000046491623\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ai_x_train, ai_x_test, ai_y_train, ai_y_test = train_test_split(train_x, train_y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1890, 28, 28, 1)\n",
      "(1890, 28, 28, 1)\n",
      "(1890, 10)\n",
      "(1890, 10)\n"
     ]
    }
   ],
   "source": [
    "print(ai_x_train.shape)\n",
    "print(ai_x_test.shape)\n",
    "print(ai_y_train.shape)\n",
    "print(ai_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 1890 samples\n",
      "Epoch 1/12\n",
      "1890/1890 [==============================] - 0s 99us/step - loss: 0.3390 - accuracy: 0.9725 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 2/12\n",
      "1890/1890 [==============================] - 0s 87us/step - loss: 0.2363 - accuracy: 0.9857 - val_loss: 0.0123 - val_accuracy: 0.9984\n",
      "Epoch 3/12\n",
      "1890/1890 [==============================] - 0s 84us/step - loss: 0.3768 - accuracy: 0.9810 - val_loss: 7.2408e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/12\n",
      "1890/1890 [==============================] - 0s 80us/step - loss: 0.2312 - accuracy: 0.9836 - val_loss: 5.1441e-04 - val_accuracy: 0.9995\n",
      "Epoch 5/12\n",
      "1890/1890 [==============================] - 0s 79us/step - loss: 0.1956 - accuracy: 0.9847 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
      "Epoch 6/12\n",
      "1890/1890 [==============================] - 0s 82us/step - loss: 0.3025 - accuracy: 0.9836 - val_loss: 0.0082 - val_accuracy: 0.9984\n",
      "Epoch 7/12\n",
      "1890/1890 [==============================] - 0s 80us/step - loss: 0.2068 - accuracy: 0.9873 - val_loss: 0.0049 - val_accuracy: 0.9989\n",
      "Epoch 8/12\n",
      "1890/1890 [==============================] - 0s 92us/step - loss: 0.0838 - accuracy: 0.9910 - val_loss: 0.0185 - val_accuracy: 0.9984\n",
      "Epoch 9/12\n",
      "1890/1890 [==============================] - 0s 79us/step - loss: 0.2163 - accuracy: 0.9894 - val_loss: 0.0382 - val_accuracy: 0.9974\n",
      "Epoch 10/12\n",
      "1890/1890 [==============================] - 0s 80us/step - loss: 0.0724 - accuracy: 0.9942 - val_loss: 0.0289 - val_accuracy: 0.9979\n",
      "Epoch 11/12\n",
      "1890/1890 [==============================] - 0s 80us/step - loss: 0.0791 - accuracy: 0.9942 - val_loss: 0.0254 - val_accuracy: 0.9979\n",
      "Epoch 12/12\n",
      "1890/1890 [==============================] - 0s 80us/step - loss: 0.0570 - accuracy: 0.9921 - val_loss: 0.0211 - val_accuracy: 0.9984\n",
      "Test loss: 0.02110765918115494\n",
      "Test accuracy: 0.9984126687049866\n"
     ]
    }
   ],
   "source": [
    "model.fit(ai_x_train, ai_y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(ai_x_test, ai_y_test))\n",
    "score = model.evaluate(ai_x_test, ai_y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3780 samples, validate on 1890 samples\n",
      "Epoch 1/12\n",
      "3780/3780 [==============================] - 0s 73us/step - loss: 0.2012 - accuracy: 0.9878 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 2/12\n",
      "3780/3780 [==============================] - 0s 68us/step - loss: 0.1569 - accuracy: 0.9905 - val_loss: 9.0209e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/12\n",
      "3780/3780 [==============================] - 0s 67us/step - loss: 0.2346 - accuracy: 0.9886 - val_loss: 0.0097 - val_accuracy: 0.9979\n",
      "Epoch 4/12\n",
      "3780/3780 [==============================] - 0s 67us/step - loss: 0.1799 - accuracy: 0.9899 - val_loss: 9.3764e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/12\n",
      "3780/3780 [==============================] - 0s 70us/step - loss: 0.1093 - accuracy: 0.9929 - val_loss: 4.4140e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/12\n",
      "3780/3780 [==============================] - 0s 68us/step - loss: 0.2325 - accuracy: 0.9884 - val_loss: 1.3105e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/12\n",
      "3780/3780 [==============================] - 0s 67us/step - loss: 0.1370 - accuracy: 0.9905 - val_loss: 4.0585e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/12\n",
      "3780/3780 [==============================] - 0s 72us/step - loss: 0.0975 - accuracy: 0.9913 - val_loss: 3.0510e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/12\n",
      "3780/3780 [==============================] - 0s 70us/step - loss: 0.1024 - accuracy: 0.9926 - val_loss: 1.4507e-09 - val_accuracy: 1.0000\n",
      "Epoch 10/12\n",
      "3780/3780 [==============================] - 0s 72us/step - loss: 0.1128 - accuracy: 0.9921 - val_loss: 3.8095e-08 - val_accuracy: 1.0000\n",
      "Epoch 11/12\n",
      "3780/3780 [==============================] - 0s 70us/step - loss: 0.1226 - accuracy: 0.9915 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/12\n",
      "3780/3780 [==============================] - 0s 73us/step - loss: 0.0803 - accuracy: 0.9947 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Test loss: 0.0\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(ai_x_test, ai_y_test))\n",
    "score = model.evaluate(ai_x_test, ai_y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.load('/kaggle/input/ai-input-test/scan-test-images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.reshape(test_x.shape[0], img_rows, img_cols, 1)\n",
    "prediction = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10010, 10)\n"
     ]
    }
   ],
   "source": [
    "print(prediction.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "total = prediction.shape[0]\n",
    "for i in range(total):\n",
    "    t = -float(\"inf\")\n",
    "    mlist = [i,0]\n",
    "    for k in enumerate(prediction[i]):\n",
    "        if k[1]>=t:\n",
    "            t = k[1]\n",
    "            mlist[1] = k[0]\n",
    "#             mlist = []\n",
    "#             mlist.append(i)\n",
    "#             mlist.append(target)\n",
    "#             if i < 20:\n",
    "#                 print(i)\n",
    "#             break\n",
    "    lst.append(mlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=lst,columns=['Id', 'Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>10005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>10006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>10007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>10008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>10009</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Category\n",
       "0          0         3\n",
       "1          1         3\n",
       "2          2         1\n",
       "3          3         3\n",
       "4          4         5\n",
       "...      ...       ...\n",
       "10005  10005         5\n",
       "10006  10006         3\n",
       "10007  10007         3\n",
       "10008  10008         2\n",
       "10009  10009         9\n",
       "\n",
       "[10010 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('prediction_air.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv (r'/kaggle/working/res.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
